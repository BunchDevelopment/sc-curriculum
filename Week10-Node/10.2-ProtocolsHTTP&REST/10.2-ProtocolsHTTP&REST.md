# HTTP and REST in-depth

## HTTP

Throughout the course, we've been working with data and services from third parties like JSON Placeholder, `openweathermap.org`, and GitHub. To do so, we've been leveraging the same request and response model used behind-the-scenes by browsers to fetch HTML, submit form data, and download files. As we've seen before when working with `fetch` and `axios`, we can use JavaScript to leverage the same communication protocol used by the browser itself (called HTTP, or **H**yper **T**ext **T**ransfer **P**rotocol) to interact with services that understand HTTP requests. While HTTP is not the only way to interact with external services, it is by far the most common because of the browser's native support. Now that we're building our own APIs to handle HTTP requests, let's take a closer look at what goes into an HTTP request and response.

### `curl`

You should already be comfortable inspecting network requests with the developer tools in the browser. You should also be comfortable making _new_ requests with JavaScript in the browser. While both of these tools are important for debugging HTTP requests in the browser, there's no requirement that the kinds of Node APIs that we're building are accessed from a browser. In fact, one of the benefits of an API that is able to expose data separately from that data's presentation in the browser is that data becomes accessible to command-line tools, mobile devices, or background processes. Because of that, we can often develop APIs more quickly from the command-line using a ubiquitous tool called `curl`.

To verify that you have `curl` installed (which you almost certainly do), type `curl --version` into your terminal.

> `curl` is installed by default (or easily accessible through a package manager) in almost \*NIX-flavored operating system (or *NIX-flavored terminal, like git-bash). You should know how to use `curl`, but there are other tools that you can often use on your local dev machine that serve similar purposes. On the command line, take a look at [`httpie`](https://httpie.org/), or take a look at some GUI-based tools like [Postman](https://www.postman.com/) or [Insomnia](https://insomnia.rest/)

### Activity 1 (Everyone)

#### Inspecting HTTP requests with `curl`

We previously tested our echo server with the browser. Now let's use `curl` to test our API more efficiently while taking a closer look at the constituent parts of an HTTP request.

0. Before we begin, make sure that your echo server is running (i.e. `node ./echoServer.js`)

1. To make a request to the `/` route, use `curl localhost:8675` (or whatever `PORT` you chose in the last activity)

2. Try making a request to other (unsupported) routes, too

3. If all goes well, you should be getting a single JSON string back as the response. To see more of what makes up the entire request, though, we can tell `curl` to be more "verbose" by providing the `-v` flag. After running `curl -v localhost:8675`, you should see the following:

    ```shell
    *   Trying ::1:8675...
    * Connected to localhost (::1) port 8675 (#0)
    > GET / HTTP/1.1
    > Host: localhost:8675
    > User-Agent: curl/7.71.1
    > Accept: */*
    >
    * Mark bundle as not supporting multiuse
    < HTTP/1.1 200 OK
    < Content-Type: application/json
    < Date: Tue, 11 Aug 2020 15:19:54 GMT
    < Connection: keep-alive
    < Transfer-Encoding: chunked
    <
    * Connection #0 to host localhost left intact
    {"message":"Welcome to the main page!"}%
    ```

    That's a lot to take in! But let's go through this output piece-by-piece:

    1. lines that start with a `*` are `curl`-specific debug output. They are not part of the HTTP request/response cycle.

    2. lines that start with `>` are part of the _request_. This request has a few important components
        - `GET` is the request **method**. We've seen these methods before, referring to them as "verbs".
        - `/` is the request **URL**. In the browser, this would be equivalent to `location.pathname`.
        - `HTTP/1.1` is the **protocol**. There are multiple versions of HTTP, with 1.1 and 2 being the most common. Each user-agent will often pick its own protocol without any input from the program constructing the request.
        - `Host`, `User-Agent`, and `Accept` are **headers**. Every HTTP request can include any of [HTTP's request headers](https://developer.mozilla.org/en-US/docs/Glossary/Request_header), which provide extra information to servers so that requests can be appropriately handled. In this case, `curl` automatically provides a [`Host` header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Host) (equivalent to `location.host` in the browser), a [`User-Agent` header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) (for [badly](https://developer.mozilla.org/en-US/docs/Web/HTTP/Browser_detection_using_the_user_agent) identifying the requesting client application, operating system, or browser version) and an [`Accept` header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept) (for telling servers which [MIME types](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types) a client can understand and expects). These three headers tell our echo server that any response type is acceptible, and that the request was made to `localhost:8675` by `curl`.

    3. lines that start with `<` are part of the _response_. This response looks similar to the request, with a few important differces:
        - There is no response method, as HTTP verbs only apply to requests.
        - `HTTP/1.1` is the **protocol**. As expected, it matches the request protocol.
        - `200 OK` is the **status code**. We've encountered [status codes](https://httpstatuses.com/) before, from the all-too-common `404 Not Found`, to the `500 Internal Server Error` codes, to the zanier `418 I'm a teapot` status code for identifying when servers [might be short and/or stout](https://httpstatuses.com/418).
        - `Content-Type` is a header that we set with `response.writeHead` in the last lesson. This lets `curl` know that the bytes that it receives from our server should be parsed as JSON before being displayed to the user.
        - `Date`, `Connection`, and `Transfer-Encoding` are all headers that are set automatically by Node's built-in `http` module. They are generally good defaults that you should rarely need to alter when building APIs of your own. We'll see later on that most frameworks add these and similar headers automatically, too.
        - the final line of output is the response **body**. Both requests and responses may _optionally_ include bodies, often depending on the type of HTTP method used in the request and the action undertaken by the server.

4. Now that we understand a bit better what goes into an HTTP request and response, let's see if we can use this newfound understanding to make our echo server a bit more useful. Let's start by creating a 404 response to let users know that they're trying to use a route that's `Not Found`. In addition to adding an `else` condition, we'll also use `response.setHeader` to make sure that both branches of our control flow response with JSON while keeping our code DRY:

    ```javascript
    const server = http.createServer((request, response) => {
        response.setHeader('Content-Type', 'application/json')

        if (request.url === "/") {
          response.writeHead(200); // if we're setting the headers above, we can write status here
          response.write(JSON.stringify({ message: "Welcome to the main page!" }));
        } else {
          response.writeHead(404);
          response.write(JSON.stringify({ message: "Not Found" }));
        }

        response.end();
    });
    ```

5. You'll notice that this is an "echo" server, but up to now we haven't included anything in our requests to echo back. What we really want from an echo server is to be able to send some text and get it sent back to us in some form. To do that, we need to stop making `GET` requests and use `POST` (just like when we _sent_ data with forms instead of _getting_ data with `axios`). In our server, let's add a `request.method` guard to our router's `if` condition:

    ```javascript
    // within the existing response handler
    if (request.url === "/" && request.method === "POST") {
      // response to the request
    } else {
      // handle 404s
    }
    ```

6. After making the change above, you'll notice that we get a `404` response even when we make requests to `/`! That's because `curl` makes `GET` requests by default. To make a `POST` request, try the following:

    ```shell
    curl -X POST localhost:8675
    ```

    ...where `-X` tells `curl` which HTTP verb to use when making the request.

7. Even though we're using a `POST` method, we're still not actually sending data to our server. To send some plain text (actually `application/x-www-form-urlencoded` text) to our server, we can use the `-d` option, like so:

    ```shell
    curl -X POST -d 'Hello echo server!' localhost:8675
    ```

8. To get our echo server to echo back the text that we send, we need to be able to parse the request's body in our request handler. Properly parsing request bodies from the bytes sent in an HTTP request is not always as straightforward as it may sound, though, so we're going to keep things simple and assume that our request will always have valid text that doesn't need any additional decoding.

    In addition, we should note that the following will _not_ work like we might expect:

    ```javascript
    response.write(JSON.stringify({ message: request.body }));
    ```

    This is because HTTP requests can be (and often _are_) so large that they need to be broken up into **chunks**. Whenever you're dealing with potentially-large requests, you can't know ahead of time how long it will take to process all of those chunks (even if a client is nice enough to send along a [`Content-Length` header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Length) like `curl` does). Because of that, requests in Node are represented as [Readable Streams](https://nodejs.org/api/stream.html#stream_readable_streams) of chunks of data. Readable Streams in Node use an Event-like system of callbacks to handle each chunk, each error, or each stream termination on its own. Here's how that would look in our echo server:

    ```javascript
    const server = http.createServer((request, response) => {
        response.setHeader("Content-Type", "application/json");

        if (request.url === "/" && request.method === "POST") {
          // we need to construct our message string piece-by-piece as data arrives
          let message = "";

          // "on()" is roughly equivalent to "addEventListener()" in the browser
          request.on("data", (chunk) => (message += chunk));

          // we don't know when (or if!) a request will end
          request.on("end", () => {
            response.writeHead(200);
            response.write(JSON.stringify({ message }));
            response.end();
          });

          // requests could error at any time
          request.on("error", () => {
            response.writeHead(500);
            response.write(JSON.stringify({ message: "Internal Server Error" }));
            response.end();
          });
        } else {
          response.writeHead(404);
          response.write(JSON.stringify({ message: "Not Found" }));
          response.end();
        }
    });
    ```

9. By this point, you should be able to use `curl -X POST -d 'Hello echo server!' localhost:8675` to get a response of `{ message: 'Hello echo server!' }` from your echo server. Nice job!

10. BONUS (after class): see if you can send JSON instead of plain text to your echo server. How would you tell the difference between plain text in a request body versus JSON payloads?

## More HTTP Verbs

By this point, we should be familiar with some aspects of GET and POST requests. But there are more HTTP verbs to explore! Let's take a look at some of these methods and how we might see them used in the wild.

| HTTP Method | Use-case                                       | Request Body\* | Response Body\* | Safe | Idempotent |
|-------------|------------------------------------------------|----------------|-----------------|------|------------|
| **GET**     | Reading resources                              | empty          | not empty       | yes  | yes        |
| **POST**    | Often (but not always) creating new resources  | not empty      | not empty       | no   | no         |
| **PUT**     | Creating or updating a specific resource       | not empty      | not empty       | no   | yes        |
| **PATCH**   | Updating a specific resource                   | not empty      | not empty       | no   | no\*\*     |
| **DELETE**  | Deleting a specific resource                   | empty          | not empty       | no   | yes        |

> \* Request and response bodies often follow these conventions, but there are a number of variations between implemenations since adherence to these guidelines is entirely up to API authors. Some common variations might include `POST` or `PATCH` updates that only return a status code instead of returning a body that contains the new or edited resource, or `DELETE` requests that use a request body to identify the resource being deleted instead of using a URL.

When talking about HTTP methods, we further group those methods into "safe" methods (that don't alter data) and "idempotent" methods (which result in the same resource state no matter how many times the same request is made). Generally speaking, `GET` is the only truly safe method and all of the methods but `POST` should strive (see below) for idempotency.

> \*\* While PATCH requests are not _required_ to be idempotent, it's usually a good idea to make sure that your PATCH requests are idempotent anyway. There are some use-cases where a single PATCH dependes on the current state of a resource, but it's often better to handle the calculation of that new state on the client instead of in the server.

This is not an exhaustive list of HTTP methods, but these are the ones you'll encounter most often, and the methods that map most cleanly to the "CRUD" operations we've seen so far in the course. You can see an exhaustive list of HTTP methods in the [Mozilla documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods)

### Activity 2 (Everyone)

#### Manipulating resources with Methods

Now that we can get an echo service to talk back to us, let's create an HTTP service that will help us keep track of some blog posts. This way, we'll be able to replace JSONPlaceholder with blog posts of our own!

0. To start, create a `server` directory in your project.

1. Let's use the echo server as boilerplate for this new server; go ahead and copy that echo server file to your new `server` directory with `cp` (e.g. `cp ./echo.js ./server/index.js`).

2. Let's start by reorganizing our routing logic a bit. What we really want is a single request handler for every `request.url` that starts with `/posts`, and separate functions for handling those requests for each method. That means that our top-level `if` condition should look like this:

    ```javascript
      if (request.url.startsWith("/posts")) {
        // TODO: handle different request methods on the /posts endpoint
      }
    ```

3. A common pattern in API design is to pull out distinct handlers for each method. In JavaScript, that collection of handlers is probably best modeled as an Object. Let's create a HANDLERS Object to hold the request handlers for each of the methods we'll be working with over our blog collection:

    ```javascript
    const HANDLERS = {
      // notice the capitalization!
      GET(request, response) {},

      // we won't need PUT in this example

      // we'll need these later, but keep commented out for now
      // POST(request, response) {},
      // PATCH(request, response) {},
      // DELETE(request, response) {},
    }
    ```

4. Now to think about how we want to store our data! We _could_ use a single in-memory Object to model our database. We could also use a more fully-featured database like Postgres or Mongo, or a service like Firestore. Instead, we're going to use a tool called [`lowdb`](https://github.com/typicode/lowdb) (from the makers of JSONPlaceholder) to write out a simple data store to a `db.json` file. This is not a good production-ready solution, but it works great for small projects and local development. To begin, you'll need to install the required dependencies with:

    ```shell
    npm install lowdb lodash-id
    ```

    ...then `require` and configure those dependencies in your `server/index.js` file like so:

    ```javascript
    const FileSync = require("lowdb/adapters/FileSync");
    const lodashId = require("lodash-id");
    const lowdb = require("lowdb");
    const adapter = new FileSync(path.join(__dirname, "db.json"));
    const db = lowdb(adapter);

    db._.mixin(lodashId);
    db.defaults({ posts: [] }).write();
    ```

    Notice the special `__dirname` path component! That is a shorthand for the current file's parent directory, regardless of the working directory of where that file might be run.

    With this configuration, we should be ready to read and write to a `db.json` file stored in our project repo.

5. At the moment, we have a number of branches that look very similar: writing a status code, writing a JSON payload, and terminating the response stream. Let's create three free-standing functions to encapsulate three of those variants into useful helpers:

    ```javascript
    const notFound = (response) => {
      response.writeHead(404);
      response.write(JSON.stringify({ message: "Not Found" }));
      response.end();
    };

    const internalServerError = (response) => {
      response.writeHead(500);
      response.write(JSON.stringify({ message: "Internal Server Error" }));
      response.end();
    };

    const ok = (response, payload) => {
      response.writeHead(200);
      response.write(JSON.stringify(payload));
      response.end();
    };
    ```

6. These helpers and handlers can now be used in our main request handler like so:

    ```javascript
    const server = http.createServer((request, response) => {
      response.setHeader("Content-Type", "application/json");

      if (request.url.startsWith("/posts")) {
        const handler = HANDLERS[request.method];

        if (handler) {
          handler(request, response);
        } else {
          notFound(response);
        }
      } else {
        notFound(response);
      }
    });
    ```

7. At the moment, our `GET` handler will never terminate the response stream. Let's use `lowdb` to query all of the posts that currently exist (which should be an empty Array):

    ```javascript
    const HANDLERS = {
      GET(request, response) {
        const posts = db.get("posts");

        ok(response, { posts: posts.value() })
      }
    }
    ```

    Make sure this works as expected with a `curl localhost:8675/posts`

8. Now for `POST`! We're going to continue to assume that we're only able to send plain text to our API, so let's assume that we want to use POST to create a new blog post with a `body` set to the text in the request body and a randomly-generated `id`. That would look something like this:

    ```javascript
    const HANDLERS = {
      // previous GET handler here
      POST(request, response) {
        let contents = ""

        request.on("data", (chunk) => (contents += chunk));

        request.on("end", () => {
          const post = db.get("posts").insert({ body: contents }).write();

          ok(response, post);
        });

        request.on("error", () => internalServerError(response));
      }
    }
    ```

    You can POST a new blog post with a request like `curl -X POST -d 'This is my new blog post' localhost:8675/posts` after which you can `GET` all of the existing blog posts. Try POST-ing a few more to build up a collection of posts! Notice how multiple POST requests with the exact same inputs will continue creating new blog posts, since POSTs are neither _safe_ nor _idempotent_.

9. As we build a collection of blog posts, you might notice that we can only GET the entire collection of posts. That's probably not how we actually want to interact with that collection all the time; most likely, we'll also want to have the option of GET-ing a single post if we already know its `id`. This pattern is commonly expressed through a resource URL that follows the pattern of `:host/:resource/:id`. In this case, that would be something like e.g. `localhost:8675/posts/42648ec2-40f9-4333-8266-9afc6f589b6a`. Let's handle the two cases we might encounter in our GET handler, then: the full collection of posts vs a single post.

    ```javascript
    const HANDLERS = {
      GET(request, response) {
        const posts = db.get("posts");

        if (request.url === "/posts") {
          // only send back the entire collection when the URL matches /posts exactly
          ok(response, { posts: posts.value() });
        } else {
          // otherwise, split up the url by '/' to try to find a post ID
          const parts = request.url.split("/");

          // TODO: explore better ways to do this!
          if (parts.length === 3) {
            const id = parts[2];
            const post = posts.getById(id).value();

            if (post) {
              ok(response, post);
            } else {
              notFound(response);
            }
          } else {
            notFound(response);
          }
        }
      },
    }
    ```

10. Of course, we need to be able to update blog posts once they're created. To do that, let's implement PATCH. Like our GET request for a single resource above, we also want to PATCH a single resource by an `id` provided as part of the request URL. That means that our PATCH logic is a combination of the logic we used for GET-ing a single post and POST-ing new content:

    ```javascript
    const HANDLERS {
      // GET and POST handlers from before still exist
      PATCH(request, response) {
        const parts = request.url.split("/");

        // as before, we can search the URL for an id
        if (parts.length === 3) {
          let contents = "";

          request.on("data", (chunk) => (contents += chunk));

          request.on("end", () => {
            const id = parts[2];

            // updateById returns a post only if one already exists
            const post = db.get("posts").updateById(id, { body: contents }).write();

            if (post) {
              ok(response, post);
            } else {
              notFound(response);
            }
          });

          request.on("error", () => internalServerError(response));
        } else {
          notFound(response);
        }
      },
    }
    ```

11. And finally, we might want to DELETE a post we had already made:

    ```javascript
    const HANDLERS {
      // previous examples here
      DELETE(request, response) {
        const parts = request.url.split("/");

        if (parts.length === 3) {
          const id = parts[2];
          const post = db.get("posts").removeById(id).write();

          if (post) {
            ok(response, post);
          } else {
            notFound(response);
          }
        } else {
          notFound(response);
        }
      },
    }
    ```

Make sure that all of these methods work locally through `curl`! In the time remaining, see if you can _break_ this API. What are the edge-cases that we haven't covered? What might be some concerns you have about sharing this API with other users?

## REST

In previous lessons or in documentation that you've seen while exploring on your own, you'll probably have heard APIs described as "RESTful". Unlike HTTP, REST (or **Re**sponsive **S**tate **T**ransfer) is not a protocol or specification; rather, REST is an architectural pattern. It is not the only way to build APIs, nor is it necessarily coupled to HTTP as a means of transferring state responsively, but we'll find that the principles of a RESTful architecture map intuitively to the HTTP protocol that we've been using thus far. And we will find that the blog API that we just built is, in fact, a RESTful API.

RESTful applications are built around 5 core values:

1. Client-Server Separation
2. Statelessness
3. Cacheable Resources
4. Uniform Interface
5. Layered Architecture

Note that nowhere do these values mention specific protocols like HTTP, or data formats like JSON. But let's look at why it's so common to find RESTful APIs that use HTTP to expose data as JSON:

### Client-Server Separation, Statelessness, and Cacheable Resources

These requirements are met simply by using HTTP. As we've already discovered, HTTP forces servers to handle generic requests that might come from any number of clients, which also enforces a general client-server separation. Additionally, HTTP requests and responses can only contain headers and bodies; all state must be included in one of those places, in every request and every response, which satisfies the statelessness requests. And finally, the consistent format of HTTP requests means that any request or response could be stored (or "cached") without requiring a persistent connection to the underlying HTTP service.

### Uniform Resouces

We've intuitively stumbled upon this principle in our existing API by leveraging HTTP methods: once you know that you can interact somehow with a "post" resource, then you can surmise that `GET /posts` would get you the entire collection of posts, `GET /posts/:id` would get you a single post, `POST /posts` would create a new post, `PATCH /posts/:id` would edit a post if it exists, `DELETE /posts/:id` would delete a post if it exists, and `PUT /posts/:id` would create a new post with a specific `id` if it didn't already exist, and update that post if it existed before. You can apply that same logic to any resource that we might want to create in the future, from "author" to "reader" and so on and so forth. That consistent pattern of accessing resources through a Unique Resource Identitfier (or URI, also known as a URL) gives RESTful APIs a discoverability missing from APIs designed without such constraints.

### Layered Architecture

And finally, we've found that the use of HTTP + JSON + Node + a format-agnostic data store have given us an architecture that can is interchange-able at the interfaces; we could exchange our database for Firestore or Postgres at any time, and the user consuming JSON from our API would never know. We could switch from Node to Deno or to Python or Ruby a compiled Go or Rust binary and, as long as the HTTP service contract was maintained, the user would never know.

Since our blog API meets all of the above specifications, you've now written your first RESTful API!
